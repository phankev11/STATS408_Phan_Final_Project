---
title: "Final Project"
author: "Kevin Phan"
format: 
  html:
    self-contained: true
    embed-resources: true
editor: visual
execute: 
  echo: true
  include: true
---

[Link to Project Github Repository](https://github.com/phankev11/STATS408_Phan_Final_Project.git)

```{r}
# Load required libraries for the project
library(tidyverse)
library(lmtest)
library(regclass)
```

## Introduction

Immediately after work or after school, the first thing I think about is dinner. However, the worst thing imaginable happens: I open my refridgerator and it's empty. I look outside the window and the weather is poor; the last thing I want to do is leave my apartment now. Luckily, with the rise of technology, a meal can be at my doorstep with a few clicks and swipes on my phone. With mobile applications like DoorDash, GrubHub, UberEats, etc., all I need to do is select which restaurant I would like to eat in tonight, choose which meal I would like to have, input my address and payment information, then almost instantly, I am given a receipt and an estimated time of arrival.

While waiting for dinner, I start to wonder what goes into that estimated time of arrival that I seemed to instantaneously receive after placing my order. If the mobile application I used can quickly predict what time I will receive my dinner, then there must be some prediction model that the application uses to determine that estimated arrival time. Intuitively, one can see that many things may influence delivery time, such as the time of the day the order was places, how busy the drivers on the application are, the size of the order, etc. With that in mind, I will focus my project on investigating which features influence delivery time.

## Data Exploration and Preparation

### Dataset

For my project, I will be using the [DoorDash ETA Prediction](https://www.kaggle.com/datasets/dharun4772/doordash-eta-prediction/data) dataset. The dataset consists of a subset of DoorDash deliveries ($n = 197428$) that occured from mid-January 2015 to mid-February 2015 in the US West Coast. Each row in the dataset corresponds to one unique delivery and contains data relating to time, the store the order was placed at, the order, the conditions of the DoorDash market at the time the order was placed, and DoorDash-provided estimates.

```{r}
# Load the dataset
delivery <- read.csv('Data/doordash.csv')
```

### Dataset Features

The DoorDash ETA Prediction dataset contains the following features:

#### Time features

-   `market_id`: given ID number for each city/region DoorDash operates in

-   `created_at`: time order is submitted to DoorDash; *UTC*

-   `actual_delivery_time`: time order is delivered; *UTC*

#### Store features

-   `store_id`: given ID number for each unique restaurant

-   `store_primary_category`: restaurant's cuisine

-   `order_protocol`: mode DoorDash order is received by restaurant

#### Order features

-   `subtotal`: value of order submitted; *\\\$0.01 USD*

-   `num_distinct_items`: number of items in order

-   `min_item_price`: price of lowest cost item in order; *\\\$0.01 USD*

-   `max_item_price`: price of highest cost item in order; *\\\$0.01 USD*

#### Market features

-   `total_onshift_dashers`: number of available dashes within 10 miles or store at time of order submission

-   `total_busy_dashers`: subset of `total_onshift_dashers` already working on different order at time of order submission

-   `total_outstanding_orders`: number of orders within 10 miles being processed at time time of order submission

#### DoorDash estimate

-   `estimated_order_place_duration`: estimated time for restaurant to receive order from DoorDash; *seconds*

-   `estimated_store_to_consumer_driving_duration`: estimated travel time between store and customer; *seconds*

### Data Cleaning and Feature Engineering

I used the following steps to clean the data and engineer needed features for my analysis:

-   I will not be using any of the store features from the dataset for my analysis, as it seems that they are incomplete and not in line with each other (i.e., each `store_id` does not have a distinct `store_primary_category`), so I omitted those columns from the data

-   I omitted incomplete entries

-   Since `market_id` is a discrete variable, I converted it to datatype factor

-   I created my dependent variable, `total_time`, for the analysis, which stores the time from `created_at` to `actual_delivery_time` in minutes

-   To match the units of `delivery_time`, I converted the DoorDash estimate features from seconds to minutes

-   Given that all of the deliveries occurred in the US West Coast, I converted `created_at` and `actual_delivery_time` from UTC to US/Pacific Time

-   For ease of interpretability, I converted the order features from cents to dollars

-   There appears to be a few different high and low periods during the day that correspond to common meal times (i.e., breakfast, lunch, dinner, late-night) and the times between meal times, respectively (*see Appendix 2.III.A.)*. I created a factor `meal_time` to capture this, defined by:

    -   `breakfast`: `created_at` between 06:00 and 10:00

    -   `lunch`: `created_at` between 10:00 and 16:00

    -   `dinner`: `created_at` between 16:00 and 21:00

    -   `late_night`: `created_at` between 21:00 and 01:00

```{r}
# Create new clean data table without store features
delivery_clean <- delivery %>%
  select(-c(store_id, store_primary_category, order_protocol))

# Omit incomplete entries
delivery_clean <- delivery_clean %>%
  na.omit()

# Convert market_id to factor
delivery_clean$market_id <- delivery_clean$market_id %>%
  as.factor()

# Create total_time variable
delivery_clean$delivery_time <- delivery_clean$actual_delivery_time %>%
  difftime(delivery_clean$created_at) %>%
  as.numeric()

# Convert DoorDash estimate features from sec to min
delivery_clean$estimated_order_place_duration <-
  delivery_clean$estimated_order_place_duration / 60

delivery_clean$estimated_store_to_consumer_driving_duration  <-
  delivery_clean$estimated_store_to_consumer_driving_duration  / 60

# Set datetime variables to UTC, then convert to PST
delivery_clean$created_at <- delivery_clean$created_at %>%
  ymd_hms(tz = 'UTC')

delivery_clean$created_at <- delivery_clean$created_at %>%
  with_tz(tzone = 'US/Pacific')

delivery_clean$actual_delivery_time <- delivery_clean$actual_delivery_time %>%
  ymd_hms(tz = 'UTC')

delivery_clean$actual_delivery_time <- delivery_clean$actual_delivery_time %>%
  with_tz(tzone = 'US/Pacific')

# Convert order features from cents to dollars
delivery_clean$subtotal <- delivery_clean$subtotal / 100

delivery_clean$min_item_price <- delivery_clean$min_item_price / 100

delivery_clean$max_item_price <- delivery_clean$max_item_price / 100

# Create meal_time variable
delivery_clean <- delivery_clean %>%
  mutate(meal_time = case_when(
                       between(hour(created_at), 0, 1) ~ 'late_night',
                       between(hour(created_at), 6, 9) ~ 'breakfast',
                       between(hour(created_at), 10, 15) ~ 'lunch',
                       between(hour(created_at), 16, 20) ~ 'dinner',
                       between(hour(created_at), 21, 24) ~ 'late_night'
                     )
        )
```

### Data Exploration

Upon investigating the data, I found the following correlations between delivery time and the features that I will use in my full model:

-   There appears to be a non-linear relationship between `total_items` and `delivery_time`, so I will include a quadratic term for `total_items` (*See Appendix 2.IV.A.*)

-   There appears to be a slight linear relationship between `max_item_price` and `delivery_time` (*See Appendix 2.IV.B.*)

-   There appears to be a slight linear relationship between `total_busy_dashers` and `delivery_time` (*See Appendix 2.IV.C.*)

-   There appears to be a slight linear relationship between `total_outstanding_orders` and `delivery_time` (*See Appendix 2.IV.D.*)

-   There appears to be a slight linear relationship between `estimated_order_place_duration` and `delivery_time` (*See Appendix 2.IV.E.*)

-   There appears to be a slight linear relationship between `estimated_store_to_consumer_driving_duration` and `delivery_time` (*See Appendix 2.IV.E.*)

-   There appears to be a slight difference in `delivery_time` between the different `market_id`s, although the distribution of `delivery_time`s appears similar between the different `market_id`s (*See Appendix 2.IV.G.*)

-   There appears to be a slight difference in `delivery_time` between the different `meal_time`s, and the distribution of `delivery_time`s appears to differ between the different `meal_time`s (*See Appendix 2.IV.H.*)

## Model Building

### Full Model

I will start with a full model that includes all of the features I believe may have some sort of effect on delivery time based on the results from the data exploration. That full model to predict delivery time includes the following variables:

-   `total_items` and a quadratic term: intuitively, a larger order should take longer to prepare, thus increasing delivery time

-   `max_item_price`: intuitively, a more expensive restaurant might care more about their preparation, thus taking longer to prepare and increasing delivery time

-   `total_busy_dashers`: intuitively, if more DoorDash drivers are currently working on a different order, then it should take longer for DoorDash to find an available driver, thus increasing delivery time

-   `total_outstanding_orders`: intuitively, if there are more outstanding orders at the moment, then it should take longer to prepare the order, thus increasing delivery time

-   `estimated_store_to_consumer_driving_duration`: intuitively, if it takes longer to get from the restaurant to the customer, delivery time should be longer

-   `market_id`: intuitively, each city has a slightly different average delivery time

-   `meal_time` and an interaction between `meal_time` and the above variables: intuitively, each meal time has a slightly different average delivery time, and the effect on delivery time from from the rest of the features may differ between meal times

To avoid issues with multicollinearity, the following features were left out of the full model:

-   `created_at` and `actual_delivery_time`, which created the features `delivery_time` and `meal_time`

-   `subtotal` and `min_item_price`, which is linearly related to `total_items` and `max_item_price`

-   `total_onshift_dashers`, which `total_busy_dashers` is a subset of

```{r}
# Create my full model
mod_full <- lm(delivery_time ~ total_items + I(total_items^2) + max_item_price +
                               total_busy_dashers + total_outstanding_orders +
                               estimated_store_to_consumer_driving_duration +
                               market_id + meal_time + total_items * meal_time +
                               I(total_items^2) * meal_time + max_item_price *
                               meal_time + total_busy_dashers * meal_time +
                               total_outstanding_orders * meal_time +
                               estimated_store_to_consumer_driving_duration *
                               meal_time + market_id * meal_time,
               data = delivery_clean)
```

#### Hypothesis Testing

Our reduced model can be written out as:

$$
\hat{delivery\_time} = \beta_0
$$

and our full model can be written out as:

$$ \hat{delivery\_time} = \beta_0 + \beta_1X_1 + \cdots + \beta_{46}X_{46} $$

Thus, we get the following hypotheses:

$$
H_0: \beta_j = 0 \text{, }1 \leq j \leq 46
$$

$$
H_\alpha: \text{One of } \beta_j \neq 0
$$

Looking at our $F$-statistic and $p$-value from the model, we can reject the null hypothesis and conclude that at least one of the features is statistically significant in predicting delivery time.

```{r}
# Pull F-statistic from model summary
summary(mod_full)$fstatistic[[1]]
# Pull p-value from model summary
pf(summary(mod_full)$fstatistic[1],
   summary(mod_full)$fstatistic[2],
   summary(mod_full)$fstatistic[3],
   lower.tail = FALSE)
```

#### Checking Model Assumptions

Based on the $F$-statistics and $p$-values given from the Bruesch-Pagan and Kolmogorov-Smirnov tests, there is statistically significant evidence to say that the assumptions of homoscedastic and normally distributed residuals are violated in the full model. Looking at the shapes of the residual plot (*See Appendix 3.I.B.i.*) and the QQ-plot (*See Appendix 3.I.B.ii.*) from the full model, I will perform a log-transformation on the response variable to see if I can correct the violations of the assumptions.

```{r}
# Breusch-Pagan test to check homoscedasticity
bptest(mod_full)
# Kolmogorov-Smirnov test to check normality
ks.test(residuals(mod_full), 'pnorm', sd = summary(mod_full)$s)
```

### Log-transformation of the Response Variable

```{r}
mod_log <- lm(log(delivery_time) ~ total_items + I(total_items^2) + 
                                   max_item_price + total_busy_dashers +
                                   total_outstanding_orders +
                                   estimated_store_to_consumer_driving_duration +
                                   market_id + meal_time + total_items *
                                   meal_time + I(total_items^2) * meal_time +
                                   max_item_price * meal_time +
                                   total_busy_dashers * meal_time +
                                   total_outstanding_orders * meal_time +
                                   estimated_store_to_consumer_driving_duration *
                                   meal_time + market_id * meal_time,
              data = delivery_clean)
```

### Variable Selection

Taking a look at the ANOVA table for our full model, it appears that some features included may not be statistically significant when added to the model to predict delivery time. Thus, I will use some

```{r}
anova(mod_full)
```

For my variable selection procedure, I will

```{r}
summary(mod_full)
```

## Appendix

### 2.III.A. Box plot of delivery time by hour of day

```{r echo = FALSE}
# Box plots of delivery time by hour of day
delivery_clean %>%
  mutate(hour = as.factor(hour(created_at))) %>%
  ggplot(aes(x = hour, y = delivery_time)) +
    geom_boxplot() +
    ylim(0, 100)
```

### 2.IV.A. Scatter plot of delivery time by total items

```{r echo = FALSE}
# Scatter plot of delivery time by total
delivery_clean %>%
  ggplot(aes(x = total_items, y = delivery_time)) +
  geom_point() +
  geom_smooth(formula = y ~ poly(x, 2), se = FALSE) +
  xlim(0, 100) +
  ylim(0, 500)
```

### 2.IV.B. Scatter plot of delivery time by max item price

```{r echo = FALSE}
# Scatter plot of delivery time by subtotal
delivery_clean %>%
  ggplot(aes(x = max_item_price, y = delivery_time)) +
  geom_point() +
  geom_smooth(formula = y ~ x, se = FALSE) +
  ylim(0, 500)
```

### 2.IV.C. Scatter plot of delivery time by total busy dashers

```{r echo = FALSE}
# Scatter plot of delivery time by total busy dashers
delivery_clean %>%
  ggplot(aes(x = total_busy_dashers, y = delivery_time)) +
  geom_point() +
  geom_smooth(formula = y ~ x) +
  ylim(0, 1000)
```

### 2.IV.D. Scatter plot of delivery time by total outstanding orders

```{r echo = FALSE}
# Scatter plot of delivery time by total outstanding orders
delivery_clean %>%
  ggplot(aes(x = total_outstanding_orders, y = delivery_time)) +
  geom_point() +
  geom_smooth(formula = y ~ x) +
  ylim(0, 1000)
```

### 2.IV.E. Scatter plot of delivery time by estimated order place duration

```{r echo = FALSE}
# Scatter plot of delivery time by estimated order place duration
delivery_clean %>%
  ggplot(aes(x = estimated_order_place_duration, y = delivery_time)) +
  geom_point() +
  geom_smooth(formula = y ~ x) +
  ylim(0, 1000)
```

### 2.IV.F. Scatter plot of delivery time by estimated store to consumer driving duration

```{r echo = FALSE}
# Scatter plot of delivery time by estimated store to consumer driving duration
delivery_clean %>%
  ggplot(aes(x = estimated_store_to_consumer_driving_duration, 
             y = delivery_time)) +
  geom_point() +
  geom_smooth(formula = y ~ x) +
  ylim(0, 1000)
```

### 2.IV.G. Box plots of delivery time by market ID

```{r echo = FALSE}
# Box plots of delivery time by market ID
delivery_clean %>%
  ggplot(aes(x = market_id, y = delivery_time)) +
  geom_boxplot() +
  ylim(0, 500)
```

### 2.IV.H. Box plots of delivery time by meal time

```{r echo = FALSE}
# Box plots of delivery time by meal time
delivery_clean %>%
  ggplot(aes(x = meal_time, y = delivery_time)) +
  geom_boxplot() +
  ylim(0, 500)
```

### 3.I.B.i. Residual plot for full model

```{r echo = FALSE}
plot(mod_full, 1)
```

### 3.I.B.ii. QQ-plot for full model

```{r echo = FALSE}
plot(mod_full, 2)
```
